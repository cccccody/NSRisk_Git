{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Defense of VaR: \n",
    "\n",
    "People like to criticize value at risk, and there has been a big push from certain quarters to favor expected shortfall (aka ES, conditional VaR, or cVaR) over VaR. I think this push is misguided (VaR is not as bad as they make it out to be and ES has its own shortcomings). \n",
    " \n",
    "For this article I wanted to look at how the ratio of ES over VaR changes over time. I suspect most practitioners expect this ratio to increase in stress environments (ES is supposed to tell us a lot about the shape of tails; we associate stress environments with tail risk; therefore ES should \"light up\" more in a stress environment than VaR). I wonder if the opposite is not true.\n",
    " \n",
    "To start, we could look at  realized VaR and ES for the S&P 500 in each calendar year from 1995 to present (you'd have at least three big market declines: tech bubble bursting in 1999, financial crisis in 2008, and current market). Depending on initial results, we could look at other indices (other countries, other asset classes) and/or hypothetical long/short portfolios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Value at Risk (VaR)\n",
    "\n",
    "A measure called value at Risk (or VaR) was created to answer the question \"how bad can things get realistically.\" It's now widely used and, in some cases, required by financial regulators to be computed and acted on.\n",
    "\n",
    "VaR is simply a percentile of a probability distribution of a financial quantity of interest. The quantity is usually either:\n",
    "- _P&L_ (profit&loss, i.e. change in wealth from the current wealth); or\n",
    "- _Rate of return_ or just _return_ of wealth; that's ending wealth divided by beginning wealth, all minus one;\n",
    "- _Log-return_, which is the logarithm of one plus the rate of return.\n",
    "\n",
    "Note that all of these quantities can in general take on both positive and negative values. Value at Risk is concerned with how much can be lost, so the convention is to reverse the sign in a way we'll describe below, giving bigger positive numbers for bigger losses.\n",
    "\n",
    "Let $X$ be the random variable giving the future value of whichever one of the quantities above is being analyzed, and let $F_t(x)$ be the cumulative distribution function (cdf) of $X$'s value at some time $t$ in the future. The Value at Risk (VaR) over time $t>0$ with probability $0\\leq p\\leq 1$ is:\n",
    "$$VaR_t(p)=-\\inf\\{x\\mid F_t(x)=Pr(X\\le x)\\ge 1-p\\}$$\n",
    "\n",
    "If $X$'s cdf $F_t$ is continuous, then the calculation simplifies to:\n",
    "$$VaR_t(p)=-F_t^{-1}(1-p);\\hspace{2em}VaR_t(p)=x \\iff \\int_{-\\infty}^{-x}f_t(y)dy=1-p$$\n",
    "where $f_t(y)$ is the probability density function of the distribution.\n",
    "\n",
    "In words, we say that $VaR_t(p)$ is the **`t-year p Value at Risk`**. $t$ could also be denominated in other time units like days. The time argument $t$ might be left implicit if it is specified elsewhere.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of VaR\n",
    "\n",
    "For example, if a bank wants to estimate how bad things can get in its trading operations, the random variable of interest might be $\\Delta w$, the change (P&L) in its trading capital $w$ by the end of tomorrow's trading day. The one-day $99\\%$ VaR for its trading operations would be the (positive) loss amount that was expected to exceed $-\\Delta w$, $99$ days out of $100$. So if the one-day $99\\%$ VaR is $\\$50,000,000$, then the bank expects to lose less than $\\$50,000,000$ on all but one out of $100$ trading days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### realized VaR and ES for the S&P 500 in each calendar year from 1995 to present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              Adj Close\nDate                   \n1995-01-03   459.109985\n1995-01-04   460.709991\n1995-01-05   460.339996\n1995-01-06   460.679993\n1995-01-09   460.829987\n...                 ...\n2020-05-22  2955.449951\n2020-05-26  2991.770020\n2020-05-27  3036.129883\n2020-05-28  3029.729980\n2020-05-29  3044.310059\n\n[6397 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Adj Close</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1995-01-03</th>\n      <td>459.109985</td>\n    </tr>\n    <tr>\n      <th>1995-01-04</th>\n      <td>460.709991</td>\n    </tr>\n    <tr>\n      <th>1995-01-05</th>\n      <td>460.339996</td>\n    </tr>\n    <tr>\n      <th>1995-01-06</th>\n      <td>460.679993</td>\n    </tr>\n    <tr>\n      <th>1995-01-09</th>\n      <td>460.829987</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-05-22</th>\n      <td>2955.449951</td>\n    </tr>\n    <tr>\n      <th>2020-05-26</th>\n      <td>2991.770020</td>\n    </tr>\n    <tr>\n      <th>2020-05-27</th>\n      <td>3036.129883</td>\n    </tr>\n    <tr>\n      <th>2020-05-28</th>\n      <td>3029.729980</td>\n    </tr>\n    <tr>\n      <th>2020-05-29</th>\n      <td>3044.310059</td>\n    </tr>\n  </tbody>\n</table>\n<p>6397 rows Ã— 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "# SP500\n",
    "# surprisingly though, popular free data feeds (AlphaVantage, quandl, FRED) only give historical data for the past 20 years.\n",
    "# so I downloaded all historical data from yahoo finance for now\n",
    "df_sp500 = pd.read_csv('SP500.csv', index_col=0, parse_dates=True, infer_datetime_format=True, header=0, usecols=['Date', 'Adj Close'])\n",
    "# 1995/1/1 - today\n",
    "start_date = pd.to_datetime('1995-1-1')\n",
    "end_date = date.today()\n",
    "df_sp500 = df_sp500.loc[start_date:end_date]\n",
    "df_sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_period = 252 # days\n",
    "p = 5 # p := VaR(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute profit/loss\n",
    "df_PL = (df_sp500-df_sp500.shift(1)).dropna()\n",
    "# compute daily percent change\n",
    "df_return = df_sp500.pct_change().dropna()\n",
    "# initize dataframe df_res for tallying end results\n",
    "df_res = pd.DataFrame(columns=['start', 'end', 'PL VaR', 'PL ES', 'return VaR', 'return ES'])\n",
    "# keep record of time periods corresponding to calculation\n",
    "df_res['start'] = df.iloc[:-time_period].index\n",
    "df_res['end'] = df.iloc[time_period:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_res.iterrows():\n",
    "    # PL in given period\n",
    "    pl = df_PL.loc[row['start']:row['end']].values\n",
    "    # PL VaR\n",
    "    pl_var = np.percentile(pl, q=p)\n",
    "    df_res.at[i, 'PL VaR'] = pl_var\n",
    "    # PL ES\n",
    "    df_res.at[i, 'PL ES'] = np.mean(pl[pl<pl_var])\n",
    "\n",
    "    # return in given period\n",
    "    returns = df_return.loc[row['start']:row['end']].values\n",
    "    # return VaR\n",
    "    returns_var = np.percentile(returns, q=p)\n",
    "    df_res.at[i, 'return VaR'] = returns_var\n",
    "    # return ES\n",
    "    df_res.at[i, 'return ES'] = np.mean(returns[returns<returns_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          start        end   PL VaR    PL ES  return VaR   return ES\n0    1995-01-03 1996-01-02 -4.03701 -5.59154 -0.00699934 -0.00991239\n252  1996-01-02 1996-12-30    -7.51   -11.49  -0.0110249  -0.0173978\n504  1996-12-30 1997-12-29   -14.76 -21.4685  -0.0169246  -0.0241019\n756  1997-12-29 1998-12-29 -22.0099 -32.2561  -0.0196425  -0.0302023\n1008 1998-12-29 1999-12-29  -23.748 -28.5216  -0.0179887  -0.0217471\n1260 1999-12-29 2000-12-27   -30.11 -41.0569  -0.0212179  -0.0290762\n1512 2000-12-27 2002-01-03  -25.184 -34.5877  -0.0209463  -0.0293034\n1764 2002-01-03 2003-01-03  -24.282 -29.2569  -0.0247886  -0.0313604\n2016 2003-01-03 2004-01-05  -14.094 -19.2192  -0.0150828  -0.0210307\n2268 2004-01-05 2005-01-04 -14.1699 -16.1108  -0.0121881  -0.0143609\n2520 2005-01-04 2006-01-04  -12.306 -14.9646  -0.0101896  -0.0125529\n2772 2006-01-04 2007-01-05  -13.178 -17.2992  -0.0100723  -0.0133822\n3024 2007-01-05 2008-01-07  -27.456 -38.0977  -0.0188157  -0.0255704\n3276 2008-01-07 2009-01-06  -47.224 -64.8269  -0.0438738  -0.0645906\n3528 2009-01-06 2010-01-06  -27.038 -32.8477  -0.0284966  -0.0388685\n3780 2010-01-06 2011-01-05 -19.7601 -30.3808  -0.0170274  -0.0268591\n4032 2011-01-05 2012-01-05   -30.53 -42.9815  -0.0248322  -0.0353909\n4284 2012-01-05 2013-01-08  -17.136 -23.4561   -0.012533  -0.0170797\n4536 2013-01-08 2014-01-08   -19.13 -25.4377  -0.0117813  -0.0155979\n4788 2014-01-08 2015-01-08  -23.542 -34.2754  -0.0125529  -0.0176679\n5040 2015-01-08 2016-01-08   -31.22 -45.7615  -0.0153141   -0.022654\n5292 2016-01-08 2017-01-09   -23.36 -37.8685  -0.0121059  -0.0187809\n5544 2017-01-09 2018-01-09  -13.846 -23.3692 -0.00532016 -0.00961511\n5796 2018-01-09 2019-01-10 -56.1819 -75.1308  -0.0208508  -0.0277996\n6048 2019-01-10 2020-01-10  -33.292   -53.88   -0.011297  -0.0186108",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start</th>\n      <th>end</th>\n      <th>PL VaR</th>\n      <th>PL ES</th>\n      <th>return VaR</th>\n      <th>return ES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1995-01-03</td>\n      <td>1996-01-02</td>\n      <td>-4.03701</td>\n      <td>-5.59154</td>\n      <td>-0.00699934</td>\n      <td>-0.00991239</td>\n    </tr>\n    <tr>\n      <th>252</th>\n      <td>1996-01-02</td>\n      <td>1996-12-30</td>\n      <td>-7.51</td>\n      <td>-11.49</td>\n      <td>-0.0110249</td>\n      <td>-0.0173978</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>1996-12-30</td>\n      <td>1997-12-29</td>\n      <td>-14.76</td>\n      <td>-21.4685</td>\n      <td>-0.0169246</td>\n      <td>-0.0241019</td>\n    </tr>\n    <tr>\n      <th>756</th>\n      <td>1997-12-29</td>\n      <td>1998-12-29</td>\n      <td>-22.0099</td>\n      <td>-32.2561</td>\n      <td>-0.0196425</td>\n      <td>-0.0302023</td>\n    </tr>\n    <tr>\n      <th>1008</th>\n      <td>1998-12-29</td>\n      <td>1999-12-29</td>\n      <td>-23.748</td>\n      <td>-28.5216</td>\n      <td>-0.0179887</td>\n      <td>-0.0217471</td>\n    </tr>\n    <tr>\n      <th>1260</th>\n      <td>1999-12-29</td>\n      <td>2000-12-27</td>\n      <td>-30.11</td>\n      <td>-41.0569</td>\n      <td>-0.0212179</td>\n      <td>-0.0290762</td>\n    </tr>\n    <tr>\n      <th>1512</th>\n      <td>2000-12-27</td>\n      <td>2002-01-03</td>\n      <td>-25.184</td>\n      <td>-34.5877</td>\n      <td>-0.0209463</td>\n      <td>-0.0293034</td>\n    </tr>\n    <tr>\n      <th>1764</th>\n      <td>2002-01-03</td>\n      <td>2003-01-03</td>\n      <td>-24.282</td>\n      <td>-29.2569</td>\n      <td>-0.0247886</td>\n      <td>-0.0313604</td>\n    </tr>\n    <tr>\n      <th>2016</th>\n      <td>2003-01-03</td>\n      <td>2004-01-05</td>\n      <td>-14.094</td>\n      <td>-19.2192</td>\n      <td>-0.0150828</td>\n      <td>-0.0210307</td>\n    </tr>\n    <tr>\n      <th>2268</th>\n      <td>2004-01-05</td>\n      <td>2005-01-04</td>\n      <td>-14.1699</td>\n      <td>-16.1108</td>\n      <td>-0.0121881</td>\n      <td>-0.0143609</td>\n    </tr>\n    <tr>\n      <th>2520</th>\n      <td>2005-01-04</td>\n      <td>2006-01-04</td>\n      <td>-12.306</td>\n      <td>-14.9646</td>\n      <td>-0.0101896</td>\n      <td>-0.0125529</td>\n    </tr>\n    <tr>\n      <th>2772</th>\n      <td>2006-01-04</td>\n      <td>2007-01-05</td>\n      <td>-13.178</td>\n      <td>-17.2992</td>\n      <td>-0.0100723</td>\n      <td>-0.0133822</td>\n    </tr>\n    <tr>\n      <th>3024</th>\n      <td>2007-01-05</td>\n      <td>2008-01-07</td>\n      <td>-27.456</td>\n      <td>-38.0977</td>\n      <td>-0.0188157</td>\n      <td>-0.0255704</td>\n    </tr>\n    <tr>\n      <th>3276</th>\n      <td>2008-01-07</td>\n      <td>2009-01-06</td>\n      <td>-47.224</td>\n      <td>-64.8269</td>\n      <td>-0.0438738</td>\n      <td>-0.0645906</td>\n    </tr>\n    <tr>\n      <th>3528</th>\n      <td>2009-01-06</td>\n      <td>2010-01-06</td>\n      <td>-27.038</td>\n      <td>-32.8477</td>\n      <td>-0.0284966</td>\n      <td>-0.0388685</td>\n    </tr>\n    <tr>\n      <th>3780</th>\n      <td>2010-01-06</td>\n      <td>2011-01-05</td>\n      <td>-19.7601</td>\n      <td>-30.3808</td>\n      <td>-0.0170274</td>\n      <td>-0.0268591</td>\n    </tr>\n    <tr>\n      <th>4032</th>\n      <td>2011-01-05</td>\n      <td>2012-01-05</td>\n      <td>-30.53</td>\n      <td>-42.9815</td>\n      <td>-0.0248322</td>\n      <td>-0.0353909</td>\n    </tr>\n    <tr>\n      <th>4284</th>\n      <td>2012-01-05</td>\n      <td>2013-01-08</td>\n      <td>-17.136</td>\n      <td>-23.4561</td>\n      <td>-0.012533</td>\n      <td>-0.0170797</td>\n    </tr>\n    <tr>\n      <th>4536</th>\n      <td>2013-01-08</td>\n      <td>2014-01-08</td>\n      <td>-19.13</td>\n      <td>-25.4377</td>\n      <td>-0.0117813</td>\n      <td>-0.0155979</td>\n    </tr>\n    <tr>\n      <th>4788</th>\n      <td>2014-01-08</td>\n      <td>2015-01-08</td>\n      <td>-23.542</td>\n      <td>-34.2754</td>\n      <td>-0.0125529</td>\n      <td>-0.0176679</td>\n    </tr>\n    <tr>\n      <th>5040</th>\n      <td>2015-01-08</td>\n      <td>2016-01-08</td>\n      <td>-31.22</td>\n      <td>-45.7615</td>\n      <td>-0.0153141</td>\n      <td>-0.022654</td>\n    </tr>\n    <tr>\n      <th>5292</th>\n      <td>2016-01-08</td>\n      <td>2017-01-09</td>\n      <td>-23.36</td>\n      <td>-37.8685</td>\n      <td>-0.0121059</td>\n      <td>-0.0187809</td>\n    </tr>\n    <tr>\n      <th>5544</th>\n      <td>2017-01-09</td>\n      <td>2018-01-09</td>\n      <td>-13.846</td>\n      <td>-23.3692</td>\n      <td>-0.00532016</td>\n      <td>-0.00961511</td>\n    </tr>\n    <tr>\n      <th>5796</th>\n      <td>2018-01-09</td>\n      <td>2019-01-10</td>\n      <td>-56.1819</td>\n      <td>-75.1308</td>\n      <td>-0.0208508</td>\n      <td>-0.0277996</td>\n    </tr>\n    <tr>\n      <th>6048</th>\n      <td>2019-01-10</td>\n      <td>2020-01-10</td>\n      <td>-33.292</td>\n      <td>-53.88</td>\n      <td>-0.011297</td>\n      <td>-0.0186108</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "# note quite by each calendar year but this will be fixed shortly\n",
    "df_res.iloc[::252]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda19daccaab569477d9dec399eeb89c3e8",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}